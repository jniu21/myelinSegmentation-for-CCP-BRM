{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C57M__IaIFfK"
      },
      "outputs": [],
      "source": [
        "# === ROI2 inference + save prob + masks @ thr 0.8/0.9 for TWO checkpoints (single notebook cell) ===\n",
        "import os\n",
        "import numpy as np\n",
        "import tifffile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# -------------------------\n",
        "# INPUTS (you provided)\n",
        "# -------------------------\n",
        "REF_TIF = \"Nov23_Crops/CCP_ROI2.tif\"        # used ONLY to compute global min/max\n",
        "RAW_TIF = \"Nov23_Crops/CCP_ROI2_crop1.tif\"  # stack to run inference on\n",
        "\n",
        "CKPT_A = \"Nov23_Crops/unet25d_runs/unet25d_k5_or_gn_drop_dice_bce_lr3e-4_clip1/best.pt\"       # pre-finetune\n",
        "CKPT_B = \"Nov23_Crops/unet25d_runs/unet25d_k5_or_finetune_crop2/best_finetune.pt\"             # finetune\n",
        "\n",
        "OUT_DIR = \"Nov23_Crops/roi2_crop1_inference\"\n",
        "THRS = (0.80, 0.90)\n",
        "\n",
        "K = 5\n",
        "PAD = K // 2  # => drop first 2 and last 2 slices automatically\n",
        "BATCH = 2     # safe for memory on 512x512; can increase batch size!!!!\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# MODEL\n",
        "# -------------------------\n",
        "def gn(num_channels: int, groups: int) -> nn.GroupNorm:\n",
        "    g = min(groups, num_channels)\n",
        "    while num_channels % g != 0 and g > 1:\n",
        "        g -= 1\n",
        "    return nn.GroupNorm(g, num_channels)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch: int, out_ch: int, groups: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.gn1   = gn(out_ch, groups)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.gn2   = gn(out_ch, groups)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.gn1(self.conv1(x)), inplace=True)\n",
        "        x = F.relu(self.gn2(self.conv2(x)), inplace=True)\n",
        "        return x\n",
        "\n",
        "class UNet2D(nn.Module):\n",
        "    def __init__(self, in_ch: int, base_ch: int = 64, groups: int = 8, dropout_bottleneck: float = 0.10):\n",
        "        super().__init__()\n",
        "        c1, c2, c3, c4, c5 = base_ch, base_ch * 2, base_ch * 4, base_ch * 8, base_ch * 16\n",
        "\n",
        "        self.enc1 = ConvBlock(in_ch, c1, groups)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = ConvBlock(c1, c2, groups)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = ConvBlock(c2, c3, groups)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc4 = ConvBlock(c3, c4, groups)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = ConvBlock(c4, c5, groups)\n",
        "        self.drop = nn.Dropout2d(p=dropout_bottleneck)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(c5, c4, 2, stride=2)\n",
        "        self.dec4 = ConvBlock(c4 + c4, c4, groups)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(c4, c3, 2, stride=2)\n",
        "        self.dec3 = ConvBlock(c3 + c3, c3, groups)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(c3, c2, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(c2 + c2, c2, groups)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(c2, c1, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(c1 + c1, c1, groups)\n",
        "\n",
        "        self.out = nn.Conv2d(c1, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "        b = self.drop(b)\n",
        "\n",
        "        d4 = self.up4(b)\n",
        "        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
        "\n",
        "        return self.out(d1)  # logits\n",
        "\n",
        "def get_model_cfg(ckpt: dict):\n",
        "    cfg = ckpt.get(\"cfg\", {}) or {}\n",
        "    base_ch = int(cfg.get(\"BASE_CH\", cfg.get(\"base_ch\", 64)))\n",
        "    gn_groups = int(cfg.get(\"GN_GROUPS\", cfg.get(\"gn_groups\", 8)))\n",
        "    drop_p = float(cfg.get(\"DROPOUT_BOTTLENECK\", cfg.get(\"dropout_bottleneck\", 0.10)))\n",
        "    return base_ch, gn_groups, drop_p\n",
        "\n",
        "def load_model(ckpt_path: str):\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    sd = ckpt.get(\"model_state\", None) or ckpt.get(\"state_dict\", None)\n",
        "    if sd is None:\n",
        "        raise KeyError(f\"Checkpoint missing model_state/state_dict: {ckpt_path}\")\n",
        "\n",
        "    base_ch, gn_groups, drop_p = get_model_cfg(ckpt)\n",
        "    model = UNet2D(in_ch=K, base_ch=base_ch, groups=gn_groups, dropout_bottleneck=drop_p).to(DEVICE)\n",
        "    model.load_state_dict(sd, strict=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# -------------------------\n",
        "# LOAD + NORMALIZE\n",
        "# -------------------------\n",
        "ref = tifffile.imread(REF_TIF)\n",
        "raw = tifffile.imread(RAW_TIF)\n",
        "\n",
        "# ensure [Z,H,W]\n",
        "if ref.ndim == 2:\n",
        "    ref = ref[None, ...]\n",
        "if raw.ndim == 2:\n",
        "    raw = raw[None, ...]\n",
        "\n",
        "ref = ref.astype(np.float32)\n",
        "raw = raw.astype(np.float32)\n",
        "\n",
        "gmin = float(np.min(ref))\n",
        "gmax = float(np.max(ref))\n",
        "print(f\"Ref {REF_TIF} shape={tuple(ref.shape)}, GLOBAL_MIN={gmin:.3f}, GLOBAL_MAX={gmax:.3f}\")\n",
        "print(f\"Eval stack {RAW_TIF} shape={tuple(raw.shape)}  (expect [Z,H,W])\")\n",
        "\n",
        "Z, H, W = raw.shape\n",
        "z_centers = list(range(PAD, Z - PAD))  # drops first 2 & last 2 for K=5\n",
        "N = len(z_centers)\n",
        "print(f\"K={K}, PAD={PAD} => centers z={z_centers[0]}..{z_centers[-1]} (N={N})\")\n",
        "\n",
        "x01 = (raw - gmin) / (gmax - gmin + 1e-12)\n",
        "x01 = np.clip(x01, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "# Build input tensor [N,K,H,W]\n",
        "x_in = np.stack([x01[z - PAD : z + PAD + 1] for z in z_centers], axis=0)  # [N,K,H,W]\n",
        "xt = torch.from_numpy(x_in).to(DEVICE)\n",
        "\n",
        "# -------------------------\n",
        "# INFERENCE + SAVE\n",
        "# -------------------------\n",
        "def run_and_save(tag: str, ckpt_path: str):\n",
        "    model = load_model(ckpt_path)\n",
        "    probs_center = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, N, BATCH):\n",
        "            logits = model(xt[i:i+BATCH])\n",
        "            probs = torch.sigmoid(logits).squeeze(1)  # [b,H,W]\n",
        "            probs_center.append(probs.detach().cpu().numpy().astype(np.float32))\n",
        "\n",
        "    probs_center = np.concatenate(probs_center, axis=0)  # [N,H,W]\n",
        "\n",
        "    # Place back into full Z volume\n",
        "    prob_vol = np.full((Z, H, W), np.nan, dtype=np.float32)\n",
        "    for i, z in enumerate(z_centers):\n",
        "        prob_vol[z] = probs_center[i]\n",
        "\n",
        "    # Masks\n",
        "    mask_vols = {}\n",
        "    for thr in THRS:\n",
        "        m = np.zeros((Z, H, W), dtype=np.uint8)\n",
        "        for i, z in enumerate(z_centers):\n",
        "            m[z] = (probs_center[i] >= thr).astype(np.uint8) * 255\n",
        "        mask_vols[thr] = m\n",
        "\n",
        "    # Save\n",
        "    base = os.path.join(OUT_DIR, f\"{os.path.splitext(os.path.basename(RAW_TIF))[0]}__{tag}\")\n",
        "    prob_path = base + \"__prob_float16.tif\"\n",
        "    tifffile.imwrite(prob_path, prob_vol.astype(np.float16))  # for visualization\n",
        "\n",
        "    for thr in THRS:\n",
        "        mpath = base + f\"__mask_thr{thr:.2f}.tif\"\n",
        "        tifffile.imwrite(mpath, mask_vols[thr])\n",
        "\n",
        "    print(f\"\\n[{tag}] ckpt={ckpt_path}\")\n",
        "    print(f\"  saved prob:  {prob_path}\")\n",
        "    for thr in THRS:\n",
        "        print(f\"  saved mask:  {base}__mask_thr{thr:.2f}.tif\")\n",
        "\n",
        "run_and_save(\"A_pre\", CKPT_A)\n",
        "run_and_save(\"B_finetune\", CKPT_B)\n",
        "\n",
        "print(f\"\\nDone. Outputs in: {OUT_DIR}\")\n"
      ]
    }
  ]
}