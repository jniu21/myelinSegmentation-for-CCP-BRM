{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLpSL0mmcD80"
      },
      "outputs": [],
      "source": [
        "# unet25d_k5_train.py\n",
        "import os, glob, csv, math, random\n",
        "import numpy as np\n",
        "import tifffile\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "@dataclass\n",
        "class CFG:\n",
        "    # data\n",
        "    PATCH_DIR: str = \"Nov23_Crops/patches_256_s128_excl_crop2buf64\"\n",
        "    LABEL_KEY: str = \"or_\"  # in npz: rb, ten, and, or\n",
        "\n",
        "    # crop2 eval\n",
        "    CROP2_RAW: str = \"Nov23_Crops/90deg_myelin_curve_CCP_crop2.tif\"\n",
        "    CROP2_GT:  str = \"Nov23_Crops/label_crop2_new.tif\"\n",
        "\n",
        "    # global normalization (from full 2960x2960 stack)\n",
        "    GLOBAL_MIN: float = 1238.0\n",
        "    GLOBAL_MAX: float = 65535.0\n",
        "\n",
        "    # 2.5D\n",
        "    K: int = 5\n",
        "    DROP_BOUNDARIES: bool = True  # drop PAD slices at each end\n",
        "    THR_EVAL: float = 0.7         # threshold for reporting crop2 Dice during training\n",
        "\n",
        "    # training\n",
        "    EPOCHS: int = 10\n",
        "    BATCH: int = 8\n",
        "    LR: float = 3e-4\n",
        "    WEIGHT_DECAY: float = 1e-4\n",
        "    CLIP_NORM: float = 1.0\n",
        "\n",
        "    # split\n",
        "    VAL_FRAC: float = 0.20\n",
        "    SEED: int = 42\n",
        "\n",
        "    # augmentation\n",
        "    AUGMENT: bool = True  # flips + 90deg rotations\n",
        "\n",
        "    # perf\n",
        "    NUM_WORKERS: int = 0\n",
        "    PIN_MEMORY: bool = False\n",
        "\n",
        "    # model\n",
        "    BASE_CH: int = 64\n",
        "    GN_GROUPS: int = 8\n",
        "    DROPOUT_BOTTLENECK: float = 0.10\n",
        "\n",
        "    # output\n",
        "    RUN_DIR: str = \"Nov23_Crops/unet25d_runs/unet25d_k5_or_gn_drop_dice_bce_lr3e-4_clip1\"\n",
        "\n",
        "cfg = CFG()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPS = 1e-8\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# REPRODUCIBILITY\n",
        "# -------------------------\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(cfg.SEED)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# SMALL HELPERS\n",
        "# -------------------------\n",
        "def global_norm_uint16_to_01(x: np.ndarray, mn: float, mx: float) -> np.ndarray:\n",
        "    x = x.astype(np.float32)\n",
        "    x = (x - mn) / (mx - mn + 1e-12)\n",
        "    return np.clip(x, 0.0, 1.0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_prec_rec_from_logits(logits: torch.Tensor, gt01: torch.Tensor, thr: float) -> Tuple[float, float, float]:\n",
        "    # logits: [N,1,H,W], gt01: [N,1,H,W]\n",
        "    probs = torch.sigmoid(logits)\n",
        "    pred = probs > thr\n",
        "    gt = gt01 > 0.5\n",
        "    tp = (pred & gt).sum().item()\n",
        "    fp = (pred & ~gt).sum().item()\n",
        "    fn = (~pred & gt).sum().item()\n",
        "    dice = (2 * tp) / (2 * tp + fp + fn + EPS)\n",
        "    prec = tp / (tp + fp + EPS)\n",
        "    rec  = tp / (tp + fn + EPS)\n",
        "    return float(dice), float(prec), float(rec)\n",
        "\n",
        "def soft_dice_loss_with_logits(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "    # logits: [N,1,H,W], targets: [N,1,H,W] float 0/1\n",
        "    probs = torch.sigmoid(logits)\n",
        "    num = 2.0 * (probs * targets).sum(dim=(1,2,3)) + EPS\n",
        "    den = (probs * probs).sum(dim=(1,2,3)) + (targets * targets).sum(dim=(1,2,3)) + EPS\n",
        "    return 1.0 - (num / den).mean()\n",
        "\n",
        "def ensure_dir(p: str):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# NPZ PATCH DATASET (2.5D)\n",
        "# -------------------------\n",
        "class TinyLRUCache:\n",
        "    \"\"\"Caches a few loaded npz dicts (keeps memory bounded).\"\"\"\n",
        "    def __init__(self, max_items: int = 8):\n",
        "        self.max_items = max_items\n",
        "        self.cache = OrderedDict()\n",
        "\n",
        "    def get(self, key: str):\n",
        "        if key in self.cache:\n",
        "            self.cache.move_to_end(key)\n",
        "            return self.cache[key]\n",
        "        return None\n",
        "\n",
        "    def put(self, key: str, val):\n",
        "        self.cache[key] = val\n",
        "        self.cache.move_to_end(key)\n",
        "        while len(self.cache) > self.max_items:\n",
        "            self.cache.popitem(last=False)\n",
        "\n",
        "class Patch25DDataset(Dataset):\n",
        "    def __init__(self, files: List[str], label_key: str, k: int, drop_boundaries: bool,\n",
        "                 global_min: float, global_max: float, augment: bool):\n",
        "        self.files = files\n",
        "        self.label_key = label_key\n",
        "        self.k = k\n",
        "        self.pad = k // 2\n",
        "        self.drop_boundaries = drop_boundaries\n",
        "        self.global_min = global_min\n",
        "        self.global_max = global_max\n",
        "        self.augment = augment\n",
        "\n",
        "        # inspect Z once to build index (assume constant Z across patches)\n",
        "        d0 = np.load(self.files[0])\n",
        "        self.Z = int(d0[\"raw\"].shape[0])\n",
        "        self.H = int(d0[\"raw\"].shape[1])\n",
        "        self.W = int(d0[\"raw\"].shape[2])\n",
        "\n",
        "        # allowed centers\n",
        "        if self.drop_boundaries:\n",
        "            self.centers = list(range(self.pad, self.Z - self.pad))\n",
        "        else:\n",
        "            self.centers = list(range(0, self.Z))\n",
        "        self.centers_per_patch = len(self.centers)\n",
        "\n",
        "        # flat index: (patch_idx, center_idx)\n",
        "        self.index = [(pi, ci) for pi in range(len(self.files)) for ci in range(self.centers_per_patch)]\n",
        "\n",
        "        self.cache = TinyLRUCache(max_items=8)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "    def _load_patch(self, path: str) -> Dict[str, np.ndarray]:\n",
        "        cached = self.cache.get(path)\n",
        "        if cached is not None:\n",
        "            return cached\n",
        "        d = np.load(path)\n",
        "        out = {\n",
        "            \"raw\": d[\"raw\"],                 # [Z,H,W]\n",
        "            \"lbl\": (d[self.label_key] > 0),  # [Z,H,W] bool\n",
        "        }\n",
        "        self.cache.put(path, out)\n",
        "        return out\n",
        "\n",
        "    def _augment_xy(self, x: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # x: [K,H,W], y: [H,W]\n",
        "        # random 0/90/180/270 rotation\n",
        "        krot = random.randint(0, 3)\n",
        "        if krot:\n",
        "            x = torch.rot90(x, k=krot, dims=(-2, -1))\n",
        "            y = torch.rot90(y, k=krot, dims=(-2, -1))\n",
        "        # random flips\n",
        "        if random.random() < 0.5:\n",
        "            x = torch.flip(x, dims=(-1,))\n",
        "            y = torch.flip(y, dims=(-1,))\n",
        "        if random.random() < 0.5:\n",
        "            x = torch.flip(x, dims=(-2,))\n",
        "            y = torch.flip(y, dims=(-2,))\n",
        "        return x, y\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        pi, ci = self.index[idx]\n",
        "        path = self.files[pi]\n",
        "        d = self._load_patch(path)\n",
        "\n",
        "        raw = d[\"raw\"]  # [Z,H,W]\n",
        "        lbl = d[\"lbl\"]  # [Z,H,W] bool\n",
        "\n",
        "        zc = self.centers[ci]\n",
        "        if self.k == 1:\n",
        "            xk = raw[zc:zc+1]\n",
        "        else:\n",
        "            xk = raw[zc - self.pad: zc + self.pad + 1]  # [K,H,W]\n",
        "        y = lbl[zc].astype(np.float32)  # [H,W]\n",
        "\n",
        "        xk = global_norm_uint16_to_01(xk, self.global_min, self.global_max)  # float32 [K,H,W]\n",
        "        x = torch.from_numpy(xk)  # [K,H,W]\n",
        "        y = torch.from_numpy(y)   # [H,W]\n",
        "\n",
        "        if self.augment:\n",
        "            x, y = self._augment_xy(x, y)\n",
        "\n",
        "        # output format\n",
        "        # x: [K,H,W] float32, y: [1,H,W] float32\n",
        "        return x, y.unsqueeze(0)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# MODEL\n",
        "# -------------------------\n",
        "def gn(num_channels: int, groups: int) -> nn.GroupNorm:\n",
        "    g = min(groups, num_channels)\n",
        "    while num_channels % g != 0 and g > 1:\n",
        "        g -= 1\n",
        "    return nn.GroupNorm(g, num_channels)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch: int, out_ch: int, groups: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.gn1 = gn(out_ch, groups)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.gn2 = gn(out_ch, groups)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.gn1(self.conv1(x)), inplace=True)\n",
        "        x = F.relu(self.gn2(self.conv2(x)), inplace=True)\n",
        "        return x\n",
        "\n",
        "class UNet2D(nn.Module):\n",
        "    def __init__(self, in_ch: int, base_ch: int = 64, groups: int = 8, dropout_bottleneck: float = 0.10):\n",
        "        super().__init__()\n",
        "        c1, c2, c3, c4, c5 = base_ch, base_ch * 2, base_ch * 4, base_ch * 8, base_ch * 16\n",
        "\n",
        "        self.enc1 = ConvBlock(in_ch, c1, groups)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = ConvBlock(c1, c2, groups)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = ConvBlock(c2, c3, groups)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc4 = ConvBlock(c3, c4, groups)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = ConvBlock(c4, c5, groups)\n",
        "        self.drop = nn.Dropout2d(p=dropout_bottleneck)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(c5, c4, 2, stride=2)\n",
        "        self.dec4 = ConvBlock(c4 + c4, c4, groups)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(c4, c3, 2, stride=2)\n",
        "        self.dec3 = ConvBlock(c3 + c3, c3, groups)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(c3, c2, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(c2 + c2, c2, groups)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(c2, c1, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(c1 + c1, c1, groups)\n",
        "\n",
        "        self.out = nn.Conv2d(c1, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "        b = self.drop(b)\n",
        "\n",
        "        d4 = self.up4(b)\n",
        "        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
        "\n",
        "        return self.out(d1)  # logits\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# EVAL ON CROP2 MANUAL GT\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def eval_on_crop2(model: nn.Module, thr: float, k: int, drop_boundaries: bool,\n",
        "                  crop2_raw_path: str, crop2_gt_path: str,\n",
        "                  global_min: float, global_max: float,\n",
        "                  batch: int = 8) -> Tuple[float, float, float]:\n",
        "    raw = tifffile.imread(crop2_raw_path).astype(np.float32)  # [Z,H,W]\n",
        "    gt  = tifffile.imread(crop2_gt_path).astype(np.float32)   # [Z,H,W]\n",
        "    assert raw.shape == gt.shape, f\"crop2 raw {raw.shape} != gt {gt.shape}\"\n",
        "    Z, H, W = raw.shape\n",
        "\n",
        "    pad = k // 2\n",
        "    x = global_norm_uint16_to_01(raw, global_min, global_max)  # [Z,H,W]\n",
        "    y = (gt > 0).astype(np.float32)                            # [Z,H,W]\n",
        "\n",
        "    if drop_boundaries:\n",
        "        z_centers = list(range(pad, Z - pad))\n",
        "    else:\n",
        "        z_centers = list(range(0, Z))\n",
        "    N = len(z_centers)\n",
        "\n",
        "    # build inputs in CPU numpy (small: 30 slices only)\n",
        "    if k == 1:\n",
        "        x_in = np.stack([x[z:z+1] for z in z_centers], axis=0)           # [N,1,H,W]\n",
        "    else:\n",
        "        x_in = np.stack([x[z-pad:z+pad+1] for z in z_centers], axis=0)   # [N,K,H,W]\n",
        "    y_in = np.stack([y[z] for z in z_centers], axis=0)                  # [N,H,W]\n",
        "\n",
        "    xt = torch.from_numpy(x_in).to(DEVICE)               # [N,K,H,W]\n",
        "    yt = torch.from_numpy(y_in).unsqueeze(1).to(DEVICE)  # [N,1,H,W]\n",
        "\n",
        "    logits_list = []\n",
        "    for i in range(0, N, batch):\n",
        "        logits_list.append(model(xt[i:i+batch]))\n",
        "    logits = torch.cat(logits_list, dim=0)\n",
        "\n",
        "    return dice_prec_rec_from_logits(logits, yt, thr=thr)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# TRAIN LOOP\n",
        "# -------------------------\n",
        "def main():\n",
        "    ensure_dir(cfg.RUN_DIR)\n",
        "\n",
        "    patch_files = sorted(glob.glob(os.path.join(cfg.PATCH_DIR, \"patch_*.npz\")))\n",
        "    if len(patch_files) == 0:\n",
        "        raise FileNotFoundError(f\"No patch_*.npz found in {cfg.PATCH_DIR}\")\n",
        "    print(f\"Found {len(patch_files)} patch volumes\")\n",
        "\n",
        "    # split on patch volumes (not per-slice), to avoid leakage\n",
        "    rng = np.random.RandomState(cfg.SEED)\n",
        "    perm = rng.permutation(len(patch_files))\n",
        "    n_val = int(round(cfg.VAL_FRAC * len(patch_files)))\n",
        "    val_ids = set(perm[:n_val].tolist())\n",
        "    tr_files = [f for i, f in enumerate(patch_files) if i not in val_ids]\n",
        "    va_files = [f for i, f in enumerate(patch_files) if i in val_ids]\n",
        "    print(f\"Train patches: {len(tr_files)} | Val patches: {len(va_files)}\")\n",
        "    print(f\"Label key: {cfg.LABEL_KEY}\")\n",
        "    print(f\"Device: {DEVICE}\")\n",
        "\n",
        "    pad = cfg.K // 2\n",
        "    print(f\"2.5D K={cfg.K} (PAD={pad}), drop boundaries: {cfg.DROP_BOUNDARIES}\")\n",
        "    # dataset info\n",
        "    ds_probe = np.load(patch_files[0])\n",
        "    Z = ds_probe[\"raw\"].shape[0]\n",
        "    centers = (Z - 2*pad) if cfg.DROP_BOUNDARIES else Z\n",
        "    print(f\"Detected Z slices per patch: {Z}\")\n",
        "    print(f\"Training centers per patch: {centers} (dropping {2*pad} boundary slices)\")\n",
        "\n",
        "    ds_tr = Patch25DDataset(\n",
        "        tr_files, label_key=cfg.LABEL_KEY, k=cfg.K, drop_boundaries=cfg.DROP_BOUNDARIES,\n",
        "        global_min=cfg.GLOBAL_MIN, global_max=cfg.GLOBAL_MAX, augment=cfg.AUGMENT\n",
        "    )\n",
        "    ds_va = Patch25DDataset(\n",
        "        va_files, label_key=cfg.LABEL_KEY, k=cfg.K, drop_boundaries=cfg.DROP_BOUNDARIES,\n",
        "        global_min=cfg.GLOBAL_MIN, global_max=cfg.GLOBAL_MAX, augment=False\n",
        "    )\n",
        "\n",
        "    # sanity check\n",
        "    x0, y0 = ds_tr[0]\n",
        "    print(f\"Sanity ds_tr[0] x: {float(x0.min()):.6f} {float(x0.max()):.6f} mean: {float(x0.mean()):.6f} shape: {tuple(x0.shape)}\")\n",
        "    print(f\"Sanity ds_tr[0] y unique: {torch.unique(y0)} y mean: {float(y0.mean()):.6f}\")\n",
        "\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=cfg.BATCH, shuffle=True,\n",
        "                       num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY, drop_last=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=cfg.BATCH, shuffle=False,\n",
        "                       num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY, drop_last=False)\n",
        "\n",
        "    model = UNet2D(in_ch=cfg.K, base_ch=cfg.BASE_CH, groups=cfg.GN_GROUPS, dropout_bottleneck=cfg.DROPOUT_BOTTLENECK).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # logging\n",
        "    log_path = os.path.join(cfg.RUN_DIR, \"log.csv\")\n",
        "    with open(log_path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow([\"epoch\", \"train_loss\", \"val_loss\", \"crop2_dice_thr\", \"crop2_precision_thr\", \"crop2_recall_thr\"])\n",
        "\n",
        "    best_dice = -1.0\n",
        "\n",
        "    for epoch in range(1, cfg.EPOCHS + 1):\n",
        "        # train\n",
        "        model.train()\n",
        "        tr_losses = []\n",
        "        pbar = tqdm(dl_tr, desc=f\"Epoch {epoch}/{cfg.EPOCHS} [train]\", leave=False)\n",
        "        for xb, yb in pbar:\n",
        "            xb = xb.to(DEVICE, non_blocking=True)  # [B,K,H,W]\n",
        "            yb = yb.to(DEVICE, non_blocking=True)  # [B,1,H,W]\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)\n",
        "\n",
        "            loss_bce = bce(logits, yb)\n",
        "            loss_dice = soft_dice_loss_with_logits(logits, yb)\n",
        "            loss = loss_bce + loss_dice\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.CLIP_NORM)\n",
        "            opt.step()\n",
        "\n",
        "            tr_losses.append(float(loss.item()))\n",
        "            pbar.set_postfix(loss=float(np.mean(tr_losses)))\n",
        "\n",
        "        train_loss = float(np.mean(tr_losses)) if tr_losses else float(\"nan\")\n",
        "\n",
        "        # val loss on held-out patches\n",
        "        model.eval()\n",
        "        va_losses = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in dl_va:\n",
        "                xb = xb.to(DEVICE, non_blocking=True)\n",
        "                yb = yb.to(DEVICE, non_blocking=True)\n",
        "                logits = model(xb)\n",
        "                loss = bce(logits, yb) + soft_dice_loss_with_logits(logits, yb)\n",
        "                va_losses.append(float(loss.item()))\n",
        "        val_loss = float(np.mean(va_losses)) if va_losses else float(\"nan\")\n",
        "\n",
        "        # eval on crop2 manual GT\n",
        "        crop2_d, crop2_p, crop2_r = eval_on_crop2(\n",
        "            model, thr=cfg.THR_EVAL, k=cfg.K, drop_boundaries=True,\n",
        "            crop2_raw_path=cfg.CROP2_RAW, crop2_gt_path=cfg.CROP2_GT,\n",
        "            global_min=cfg.GLOBAL_MIN, global_max=cfg.GLOBAL_MAX,\n",
        "            batch=cfg.BATCH\n",
        "        )\n",
        "\n",
        "        # print epoch summary\n",
        "        print(f\"Epoch {epoch:03d}/{cfg.EPOCHS} | train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n",
        "              f\"| crop2 Dice@{cfg.THR_EVAL:.2f}={crop2_d:.4f} P={crop2_p:.4f} R={crop2_r:.4f}\")\n",
        "\n",
        "        # log\n",
        "        with open(log_path, \"a\", newline=\"\") as f:\n",
        "            w = csv.writer(f)\n",
        "            w.writerow([epoch, train_loss, val_loss, crop2_d, crop2_p, crop2_r])\n",
        "\n",
        "        # save last\n",
        "        ckpt = {\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"opt_state\": opt.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"cfg\": cfg.__dict__,\n",
        "        }\n",
        "        torch.save(ckpt, os.path.join(cfg.RUN_DIR, \"last.pt\"))\n",
        "\n",
        "        # save best by crop2 Dice@thr\n",
        "        if crop2_d > best_dice:\n",
        "            best_dice = crop2_d\n",
        "            torch.save(ckpt, os.path.join(cfg.RUN_DIR, \"best.pt\"))\n",
        "\n",
        "    print(f\"\\nDone. Best crop2 Dice@{cfg.THR_EVAL:.2f}: {best_dice:.4f}\")\n",
        "    print(f\"Saved in: {cfg.RUN_DIR}\")\n",
        "    print(\"Artifacts: best.pt, last.pt, log.csv\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}