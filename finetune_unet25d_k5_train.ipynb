{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1a77AgDeL-P"
      },
      "outputs": [],
      "source": [
        "import os, math, random\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import tifffile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "@dataclass\n",
        "class FTConfig:\n",
        "    # stage-1 checkpoint (K=5, OR pseudo-labels)\n",
        "    CKPT_PATH: str = \"Nov23_Crops/unet25d_runs/unet25d_k5_or_gn_drop_dice_bce_lr3e-4_clip1/best.pt\"\n",
        "\n",
        "    # crop2 raw and manual GT\n",
        "    CROP2_RAW: str = \"Nov23_Crops/90deg_myelin_curve_CCP_crop2.tif\"\n",
        "    CROP2_GT:  str = \"Nov23_Crops/label_crop2_new.tif\"\n",
        "\n",
        "    # global normalization (same as before)\n",
        "    GLOBAL_MIN: float = 1238.0\n",
        "    GLOBAL_MAX: float = 65535.0\n",
        "\n",
        "    # 2.5D\n",
        "    K: int = 5\n",
        "    PAD: int = 2   # K=5 -> pad=2\n",
        "\n",
        "    # training hyperparams\n",
        "    EPOCHS: int = 20     # you can stop early if dev AUPRC plateaus\n",
        "    BATCH: int = 4\n",
        "    LR: float = 1e-4     # smaller LR for fine-tuning\n",
        "    WEIGHT_DECAY: float = 1e-5\n",
        "    CLIP_NORM: float = 1.0\n",
        "\n",
        "    # device\n",
        "    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # output\n",
        "    RUN_DIR: str = \"Nov23_Crops/unet25d_runs/unet25d_k5_or_finetune_crop2\"\n",
        "\n",
        "cfg = FTConfig()\n",
        "os.makedirs(cfg.RUN_DIR, exist_ok=True)\n",
        "EPS = 1e-8\n",
        "\n",
        "# -------------------------\n",
        "# REPRO\n",
        "# -------------------------\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_everything(42)\n",
        "\n",
        "# -------------------------\n",
        "# MODEL (same as stage 1)\n",
        "# -------------------------\n",
        "def gn(num_channels: int, groups: int) -> nn.GroupNorm:\n",
        "    g = min(groups, num_channels)\n",
        "    while num_channels % g != 0 and g > 1:\n",
        "        g -= 1\n",
        "    return nn.GroupNorm(g, num_channels)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch: int, out_ch: int, groups: int):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.gn1 = gn(out_ch, groups)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.gn2 = gn(out_ch, groups)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.gn1(self.conv1(x)), inplace=True)\n",
        "        x = F.relu(self.gn2(self.conv2(x)), inplace=True)\n",
        "        return x\n",
        "\n",
        "class UNet2D(nn.Module):\n",
        "    def __init__(self, in_ch: int, base_ch: int = 64, groups: int = 8, dropout_bottleneck: float = 0.10):\n",
        "        super().__init__()\n",
        "        c1, c2, c3, c4, c5 = base_ch, base_ch * 2, base_ch * 4, base_ch * 8, base_ch * 16\n",
        "\n",
        "        self.enc1 = ConvBlock(in_ch, c1, groups)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = ConvBlock(c1, c2, groups)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = ConvBlock(c2, c3, groups)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc4 = ConvBlock(c3, c4, groups)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = ConvBlock(c4, c5, groups)\n",
        "        self.drop = nn.Dropout2d(p=dropout_bottleneck)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(c5, c4, 2, stride=2)\n",
        "        self.dec4 = ConvBlock(c4 + c4, c4, groups)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(c4, c3, 2, stride=2)\n",
        "        self.dec3 = ConvBlock(c3 + c3, c3, groups)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(c3, c2, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(c2 + c2, c2, groups)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(c2, c1, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(c1 + c1, c1, groups)\n",
        "\n",
        "        self.out = nn.Conv2d(c1, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "        b = self.drop(b)\n",
        "\n",
        "        d4 = self.up4(b)\n",
        "        d4 = self.dec4(torch.cat([d4, e4], dim=1))\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
        "\n",
        "        return self.out(d1)  # logits\n",
        "\n",
        "# -------------------------\n",
        "# AUPRC / Dice metrics\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def binary_auprc_from_logits(logits: torch.Tensor, y: torch.Tensor) -> float:\n",
        "    \"\"\"Flatten, compute AUPRC over pixels.\"\"\"\n",
        "    probs = torch.sigmoid(logits).flatten().cpu().numpy().astype(np.float64)\n",
        "    y_true = y.flatten().cpu().numpy().astype(np.int32)\n",
        "\n",
        "    # sort by decreasing probability\n",
        "    order = np.argsort(-probs)\n",
        "    probs = probs[order]\n",
        "    y_true = y_true[order]\n",
        "\n",
        "    tp = 0.0\n",
        "    fp = 0.0\n",
        "    tps = []\n",
        "    fps = []\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == 1:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "        tps.append(tp)\n",
        "        fps.append(fp)\n",
        "\n",
        "    tps = np.asarray(tps)\n",
        "    fps = np.asarray(fps)\n",
        "\n",
        "    P = tps[-1]  # total positives\n",
        "    if P == 0:\n",
        "        return 0.0\n",
        "\n",
        "    precision = tps / (tps + fps + 1e-8)\n",
        "    recall    = tps / P\n",
        "\n",
        "    # integrate precision(recall) with trapezoidal rule\n",
        "    # need recall sorted ascending\n",
        "    order_r = np.argsort(recall)\n",
        "    recall = recall[order_r]\n",
        "    precision = precision[order_r]\n",
        "    auprc = np.trapz(precision, recall)\n",
        "    return float(auprc)\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_from_logits(logits: torch.Tensor, y: torch.Tensor, thr: float = 0.5) -> float:\n",
        "    probs = torch.sigmoid(logits)\n",
        "    pred = probs > thr\n",
        "    gt = y > 0.5\n",
        "    tp = (pred & gt).sum().item()\n",
        "    fp = (pred & ~gt).sum().item()\n",
        "    fn = (~pred & gt).sum().item()\n",
        "    if tp + fp + fn == 0:\n",
        "        return 0.0\n",
        "    return float((2 * tp) / (2 * tp + fp + fn + 1e-8))\n",
        "\n",
        "# -------------------------\n",
        "# Dataset for Crop2 fine-tuning\n",
        "# -------------------------\n",
        "def aug_flip_rot(x: torch.Tensor, y: torch.Tensor):\n",
        "    # x: [B,C,H,W], y: [B,1,H,W]\n",
        "    k = random.randint(0, 3)\n",
        "    if k:\n",
        "        x = torch.rot90(x, k=k, dims=(-2, -1))\n",
        "        y = torch.rot90(y, k=k, dims=(-2, -1))\n",
        "    if random.random() < 0.5:\n",
        "        x = torch.flip(x, dims=(-1,))\n",
        "        y = torch.flip(y, dims=(-1,))\n",
        "    if random.random() < 0.5:\n",
        "        x = torch.flip(x, dims=(-2,))\n",
        "        y = torch.flip(y, dims=(-2,))\n",
        "    return x, y\n",
        "\n",
        "class Crop2FineTuneDataset(Dataset):\n",
        "    \"\"\"\n",
        "    2.5D K=5 patches from specified quadrants of Crop2.\n",
        "    Each sample = one center slice z with its K-slice neighborhood and center-slice GT.\n",
        "    \"\"\"\n",
        "    def __init__(self, raw: np.ndarray, gt: np.ndarray,\n",
        "                 quads: List[Tuple[int,int,int,int]],\n",
        "                 k: int = 5, augment: bool = False):\n",
        "        super().__init__()\n",
        "        self.raw = raw.astype(np.float32)  # [Z,H,W]\n",
        "        self.gt = gt.astype(np.float32)    # [Z,H,W]\n",
        "        self.quads = quads\n",
        "        self.k = k\n",
        "        self.pad = k // 2\n",
        "        self.augment = augment\n",
        "\n",
        "        Z, H, W = raw.shape\n",
        "        # valid centers: z=2..27 for K=5 with Z=30 (common26)\n",
        "        self.z_centers = list(range(self.pad, Z - self.pad))\n",
        "        self.samples = []  # (quad_idx, z_center)\n",
        "\n",
        "        for qi, (y0,y1,x0,x1) in enumerate(self.quads):\n",
        "            for z in self.z_centers:\n",
        "                self.samples.append((qi, z))\n",
        "\n",
        "        # pre-normalize whole volume once (global min/max)\n",
        "        self.raw_n = (self.raw - cfg.GLOBAL_MIN) / (cfg.GLOBAL_MAX - cfg.GLOBAL_MIN + 1e-12)\n",
        "        self.raw_n = np.clip(self.raw_n, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        qi, z = self.samples[idx]\n",
        "        y0,y1,x0,x1 = self.quads[qi]\n",
        "\n",
        "        xk = self.raw_n[z - self.pad : z + self.pad + 1, y0:y1, x0:x1]   # [K,256,256]\n",
        "        yk = (self.gt[z, y0:y1, x0:x1] > 0).astype(np.float32)          # [256,256]\n",
        "\n",
        "        x = torch.from_numpy(xk)                       # [K,H,W]\n",
        "        y = torch.from_numpy(yk).unsqueeze(0)          # [1,H,W]\n",
        "\n",
        "        if self.augment:\n",
        "            xb = x.unsqueeze(0)\n",
        "            yb = y.unsqueeze(0)\n",
        "            xb, yb = aug_flip_rot(xb, yb)\n",
        "            x = xb.squeeze(0)\n",
        "            y = yb.squeeze(0)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# -------------------------\n",
        "# Dice loss\n",
        "# -------------------------\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, eps: float = 1e-8):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        probs = torch.sigmoid(logits)\n",
        "        probs = probs.view(probs.size(0), -1)\n",
        "        targets = targets.view(targets.size(0), -1)\n",
        "        inter = (probs * targets).sum(dim=1)\n",
        "        denom = probs.sum(dim=1) + targets.sum(dim=1)\n",
        "        dice = (2 * inter + self.eps) / (denom + self.eps)\n",
        "        return 1.0 - dice.mean()\n",
        "\n",
        "# -------------------------\n",
        "# Build data + model\n",
        "# -------------------------\n",
        "# load crop2 volumes\n",
        "raw = tifffile.imread(cfg.CROP2_RAW).astype(np.float32)  # [Z,H,W]\n",
        "gt  = tifffile.imread(cfg.CROP2_GT).astype(np.float32)   # [Z,H,W]\n",
        "Z,H,W = raw.shape\n",
        "assert H == 512 and W == 512 and Z == 30, (raw.shape, \"unexpected crop2 shape\")\n",
        "\n",
        "# quadrants: (y0,y1,x0,x1)\n",
        "TL = (0,256,   0,256)\n",
        "TR = (0,256, 256,512)   # dev quadrant we used for k selection\n",
        "BL = (256,512, 0,256)\n",
        "BR = (256,512,256,512)\n",
        "\n",
        "train_quads = [TL, BL, BR]\n",
        "val_quads   = [TR]\n",
        "\n",
        "ds_tr = Crop2FineTuneDataset(raw, gt, train_quads, k=cfg.K, augment=True)\n",
        "ds_va = Crop2FineTuneDataset(raw, gt, val_quads,   k=cfg.K, augment=False)\n",
        "\n",
        "print(f\"Train samples: {len(ds_tr)} (quads={len(train_quads)}, z-centers={len(ds_tr.z_centers)})\")\n",
        "print(f\"Val samples:   {len(ds_va)} (quad=TR, z-centers={len(ds_va.z_centers)})\")\n",
        "\n",
        "dl_tr = DataLoader(ds_tr, batch_size=cfg.BATCH, shuffle=True,\n",
        "                   num_workers= 0, pin_memory=True, drop_last=True)\n",
        "dl_va = DataLoader(ds_va, batch_size=cfg.BATCH, shuffle=False,\n",
        "                   num_workers= 0, pin_memory=True, drop_last=False)\n",
        "\n",
        "# load checkpoint & build model with same hyperparams\n",
        "ckpt = torch.load(cfg.CKPT_PATH, map_location=\"cpu\")\n",
        "cfg_ckpt = ckpt.get(\"cfg\", {})\n",
        "base_ch = int(cfg_ckpt.get(\"BASE_CH\", cfg_ckpt.get(\"base_ch\", 64)))\n",
        "gn_groups = int(cfg_ckpt.get(\"GN_GROUPS\", cfg_ckpt.get(\"gn_groups\", 8)))\n",
        "drop_p = float(cfg_ckpt.get(\"DROPOUT_BOTTLENECK\", cfg_ckpt.get(\"dropout_bottleneck\", 0.10)))\n",
        "\n",
        "model = UNet2D(in_ch=cfg.K, base_ch=base_ch, groups=gn_groups,\n",
        "               dropout_bottleneck=drop_p).to(cfg.DEVICE)\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "print(\"Loaded base model from:\", cfg.CKPT_PATH)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)\n",
        "dice_loss_fn = DiceLoss()\n",
        "bce_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "log_path = os.path.join(cfg.RUN_DIR, \"finetune_log.csv\")\n",
        "with open(log_path, \"w\") as f:\n",
        "    f.write(\"epoch,train_loss,val_loss,val_auprc,val_dice0.5\\n\")\n",
        "\n",
        "best_auprc = -1.0\n",
        "best_path = os.path.join(cfg.RUN_DIR, \"best_finetune.pt\")\n",
        "last_path = os.path.join(cfg.RUN_DIR, \"last_finetune.pt\")\n",
        "\n",
        "# -------------------------\n",
        "# Fine-tuning loop\n",
        "# -------------------------\n",
        "for epoch in range(1, cfg.EPOCHS + 1):\n",
        "    # --- train ---\n",
        "    model.train()\n",
        "    tr_losses = []\n",
        "    pbar = tqdm(dl_tr, desc=f\"Epoch {epoch}/{cfg.EPOCHS} [train]\", leave=False)\n",
        "    for xb, yb in pbar:\n",
        "        xb = xb.to(cfg.DEVICE, non_blocking=True)\n",
        "        yb = yb.to(cfg.DEVICE, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(xb)\n",
        "\n",
        "        loss_d = dice_loss_fn(logits, yb)\n",
        "        loss_b = bce_loss_fn(logits, yb)\n",
        "        loss = loss_d + loss_b\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.CLIP_NORM)\n",
        "        optimizer.step()\n",
        "\n",
        "        tr_losses.append(float(loss.item()))\n",
        "        pbar.set_postfix(loss=f\"{np.mean(tr_losses):.4f}\")\n",
        "\n",
        "    train_loss = float(np.mean(tr_losses)) if tr_losses else float(\"nan\")\n",
        "\n",
        "    # --- validation (AUPRC + Dice@0.5) ---\n",
        "    model.eval()\n",
        "    va_losses = []\n",
        "    logits_all = []\n",
        "    y_all = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dl_va:\n",
        "            xb = xb.to(cfg.DEVICE, non_blocking=True)\n",
        "            yb = yb.to(cfg.DEVICE, non_blocking=True)\n",
        "            logits = model(xb)\n",
        "            loss = dice_loss_fn(logits, yb) + bce_loss_fn(logits, yb)\n",
        "            va_losses.append(float(loss.item()))\n",
        "            logits_all.append(logits.cpu())\n",
        "            y_all.append(yb.cpu())\n",
        "\n",
        "    val_loss = float(np.mean(va_losses)) if va_losses else float(\"nan\")\n",
        "    logits_all = torch.cat(logits_all, dim=0)\n",
        "    y_all = torch.cat(y_all, dim=0)\n",
        "\n",
        "    val_auprc = binary_auprc_from_logits(logits_all, y_all)\n",
        "    val_dice = dice_from_logits(logits_all, y_all, thr=0.5)\n",
        "\n",
        "    print(f\"Epoch {epoch:03d}/{cfg.EPOCHS} | \"\n",
        "          f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} | \"\n",
        "          f\"val AUPRC={val_auprc:.4f} Dice@0.5={val_dice:.4f}\")\n",
        "\n",
        "    with open(log_path, \"a\") as f:\n",
        "        f.write(f\"{epoch},{train_loss},{val_loss},{val_auprc},{val_dice}\\n\")\n",
        "\n",
        "    # save last\n",
        "    torch.save({\"epoch\": epoch,\n",
        "                \"model_state\": model.state_dict(),\n",
        "                \"optimizer_state\": optimizer.state_dict(),\n",
        "                \"cfg\": cfg_ckpt}, last_path)\n",
        "\n",
        "    # save best by AUPRC\n",
        "    if val_auprc > best_auprc:\n",
        "        best_auprc = val_auprc\n",
        "        torch.save({\"epoch\": epoch,\n",
        "                    \"model_state\": model.state_dict(),\n",
        "                    \"optimizer_state\": optimizer.state_dict(),\n",
        "                    \"cfg\": cfg_ckpt,\n",
        "                    \"best_val_auprc\": best_auprc}, best_path)\n",
        "\n",
        "print(\"\\nFine-tuning done.\")\n",
        "print(\"Best dev AUPRC:\", best_auprc)\n",
        "print(\"Saved:\", log_path)\n",
        "print(\"      \", best_path)\n",
        "print(\"      \", last_path)\n"
      ]
    }
  ]
}